\chapter{Podsumowanie}
\label{cha:podsumowanie}  

Praca poświęcona była analizie zachowania i porównaniu czterech algorytmów indukcji gramatyk formalnych: \textit{RPNI}, \textit{L*}, \textit{ALERGIA} oraz \textit{GIG}. W jej ramach stworzono środowisko eksperymentalne, które umożliwiło ocenę tych metod pod kątem wydajności, dokładności oraz zdolności do uogólniania danych. Implementacja została zrealizowana w języku Python z wykorzystaniem bibliotek \textit{aalpy}, \textit{pygad}, \textit{numpy}, \textit{automata-lib} oraz \textit{pydot}, co pozwoliło na przeprowadzenie eksperymentów i wizualizację wyników.

Wykonana praca obejmuje opracowanie implementacji algorytmu \textit{GIG} z wykorzystaniem frameworku \textit{pygad}. W ramach tej implementacji autor zaadaptował operacje genetyczne, takie jak krzyżowanie i mutacja, opracował funkcje generujące populacje oraz zdefiniował funkcję przystosowania (\textit{fitness function}). Ponadto, zaimplementowano moduły uruchamiające eksperymenty, odpowiedzialne za konfigurację parametrów testowych i inicjalizację ich przebiegu. Oprócz tego autor stworzył funkcje wspomagające, takie jak mechanizmy generowania zbiorów danych, dodawania szumu do danych oraz obliczania jakości modeli. Kod został zaprojektowany w sposób umożliwiający jego rozszerzanie oraz ponowne wykorzystanie w przyszłych badaniach.  

Eksperymenty pozwoliły na ocenę skuteczności i wydajności badanych algorytmów. Algorytm \textit{L*} generował minimalne automaty deterministyczne (\textit{DFA}) przy niskiej liczbie zapytań o równoważność (\textit{EQ}), jednak liczba zapytań o przynależność (\textit{MQ}) rosła wykładniczo wraz ze złożonością problemu. Algorytm \textit{RPNI} wyróżniał się prostotą, niską złożonością i skutecznym uogólnianiem danych. Algorytm \textit{GIG}, choć oferował elastyczność dzięki zastosowaniu metod ewolucyjnych, nie zawsze przewyższał prostsze metody pod względem wyników, a losowa inicjalizacja populacji często prowadziła do lepszych rezultatów niż inicjalizacja warstwowa. Algorytm \textit{ALERGIA} wykazał odporność na niewielkie zakłócenia, jednak jego skuteczność malała wraz ze wzrostem poziomu szumu, co czyni go bardziej odpowiednim dla danych probabilistycznych o umiarkowanym poziomie zakłóceń.  

W trakcie realizacji pracy napotkano kilka wyzwań teoretycznych i praktycznych, które wymagały odpowiednich rozwiązań. Pierwszym problemem była ocena jakości modeli stochastycznych. Standardowe metryki, takie jak macierz pomyłek, nie mogły zostać zastosowane z uwagi na probabilistyczny charakter automatu. Rozwiązaniem było generowanie dużej liczby losowych zdań z automatu wynikowego i ich weryfikacja przez poprawny automat referencyjny. Pozwoliło to na przybliżoną ocenę jakości modeli.

Kolejnym wyzwaniem była sprawiedliwa ocena czasu działania algorytmu \textit{RPNI} w zależności od rozmiaru alfabetu. Czas działania algorytmu zależy od liczby stanów w akceptorze prefiksów (\textit{PTA}), która z kolei wynika z liczby i długości przykładów w danych wejściowych. Liczba stanów w \textit{PTA} jest trudna do przewidzenia i różni się w zależności od alfabetu, co utrudniało porównanie wyników. Problem rozwiązano poprzez ręczne dobieranie liczby przykładów, tak aby liczba stanów w \textit{PTA} była porównywalna dla różnych rozmiarów alfabetów.

Największym wyzwaniem w przypadku algorytmu \textit{GIG} było dobranie odpowiedniej funkcji przystosowania (\textit{fitness function}). Zbyt duży nacisk na minimalizację liczby stanów w automacie prowadził do utraty dokładności klasyfikacji, podczas gdy priorytetowanie poprawności klasyfikacji skutkowało generowaniem nadmiernie złożonych modeli. Rozwiązaniem okazało się empiryczne dostosowanie funkcji przystosowania, które uwzględniało zarówno minimalizację automatu, jak i jego dokładność. Funkcja wymagała jednak dopasowywania do specyfiki każdego przypadku, co wskazuje na potrzebę dalszych badań w tym obszarze.

Podsumowując, praca pozwoliła na stworzenie wszechstronnego środowiska testowego oraz przeprowadzenie szczegółowej analizy porównawczej algorytmów indukcji gramatyk formalnych. Wyniki eksperymentów wskazują na konieczność dopasowania wyboru algorytmu do specyfiki problemu i charakterystyki danych. Środowisko jest gotowe do dalszej rozbudowy, a przyszłe badania mogą objąć testy na danych rzeczywistych, optymalizację obecnych metod oraz analizę dodatkowych algorytmów.


\section{Dalsze kierunki rozwoju}
Możliwości dalszego rozwoju obejmują powtórzenie eksperymentów na bardziej złożonych lub rzeczywistych danych, co pozwoliłoby na dokładniejsze zbadanie praktycznych zastosowań algorytmów. Ponadto warto przeprowadzić dodatkowe analizy dla innych metod indukcji gramatyk formalnych, które nie zostały uwzględnione w tej pracy, w celu poszerzenia porównania i oceny ich skuteczności w różnych warunkach.
